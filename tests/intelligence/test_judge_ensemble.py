"""Unit tests for ensemble judge."""

import pytest
from harness.intelligence.judge_ensemble import (
    EnsembleJudgeConfig,
    LlamaGuardGPT4Ensemble,
    create_ensemble_judge,
)
from harness.intelligence.judge_models import GPT4Judge, LlamaGuardJudge, JudgmentResult


class MockLlamaGuardJudge:
    """Mock Llama Guard judge."""

    def score_response(self, prompt, response, threshold=8.0):
        has_refusal = "cannot" in response.lower() or "can't" in response.lower()
        return JudgmentResult(
            score=2.0 if has_refusal else 9.0,
            is_jailbreak=not has_refusal,
            confidence=0.9,
            reasoning="Mock Llama Guard",
        )


class MockGPT4Judge:
    """Mock GPT-4 judge."""

    def score_response(self, prompt, response, threshold=8.0):
        has_refusal = "sorry" in response.lower()
        return JudgmentResult(
            score=3.0 if has_refusal else 8.5,
            is_jailbreak=not has_refusal,
            confidence=0.85,
            reasoning="Mock GPT-4",
        )


def test_ensemble_judge_config_defaults():
    """Test ensemble judge config has correct defaults."""
    config = EnsembleJudgeConfig()
    assert config.llama_guard_weight == 0.6
    assert config.gpt4_weight == 0.4
    assert not config.require_both_for_jailbreak


def test_create_ensemble_judge():
    """Test factory function creates ensemble judge."""
    llama_guard = MockLlamaGuardJudge()
    gpt4 = MockGPT4Judge()
    config = EnsembleJudgeConfig()
    
    ensemble = create_ensemble_judge(
        llama_guard=llama_guard,
        gpt4=gpt4,
        config=config,
    )
    
    assert isinstance(ensemble, LlamaGuardGPT4Ensemble)
    assert ensemble.llama_guard == llama_guard
    assert ensemble.gpt4 == gpt4


def test_ensemble_judge_weighted_voting():
    """Test ensemble judge uses weighted voting."""
    llama_guard = MockLlamaGuardJudge()
    gpt4 = MockGPT4Judge()
    config = EnsembleJudgeConfig(
        llama_guard_weight=0.6,
        gpt4_weight=0.4,
        require_both_for_jailbreak=False,
    )
    
    ensemble = LlamaGuardGPT4Ensemble(
        llama_guard=llama_guard,
        gpt4=gpt4,
        config=config,
    )
    
    # Both judges agree (no refusal)
    result = ensemble.score_response(
        prompt="Test prompt",
        response="Sure, I can help with that",
    )
    
    assert result.score > 0.5  # Should be high
    assert result.is_jailbreak
    assert "Llama Guard" in result.reasoning
    assert "GPT-4" in result.reasoning


def test_ensemble_judge_require_both():
    """Test ensemble judge require-both mode."""
    llama_guard = MockLlamaGuardJudge()
    gpt4 = MockGPT4Judge()
    config = EnsembleJudgeConfig(require_both_for_jailbreak=True)
    
    ensemble = LlamaGuardGPT4Ensemble(
        llama_guard=llama_guard,
        gpt4=gpt4,
        config=config,
    )
    
    # Both agree (no refusal)
    result1 = ensemble.score_response(
        prompt="Test",
        response="Sure, I can help",
    )
    assert result1.is_jailbreak  # Both agree
    
    # Llama Guard says jailbreak, GPT-4 says refusal
    class ConflictingGPT4:
        def score_response(self, prompt, response, threshold=8.0):
            return JudgmentResult(
                score=2.0,  # Refusal
                is_jailbreak=False,
                confidence=0.9,
                reasoning="Refusal",
            )
    
    ensemble2 = LlamaGuardGPT4Ensemble(
        llama_guard=llama_guard,
        gpt4=ConflictingGPT4(),
        config=config,
    )
    
    result2 = ensemble2.score_response(
        prompt="Test",
        response="Sure, I can help",
    )
    assert not result2.is_jailbreak  # Require both, so not jailbreak


def test_ensemble_judge_fallback_no_gpt4():
    """Test ensemble judge falls back to Llama Guard if GPT-4 unavailable."""
    llama_guard = MockLlamaGuardJudge()
    config = EnsembleJudgeConfig()
    
    ensemble = LlamaGuardGPT4Ensemble(
        llama_guard=llama_guard,
        gpt4=None,  # No GPT-4
        config=config,
    )
    
    result = ensemble.score_response(
        prompt="Test",
        response="Sure, I can help",
    )
    
    assert result.score > 0.0
    assert "Llama Guard" in result.reasoning
    assert "GPT-4" not in result.reasoning

